{"cells":[{"cell_type":"markdown","metadata":{"id":"Kw01g10zBjZr"},"source":["## Урок 1. Алгоритм линейной регрессии. Градиентный спуск"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"ak8b3KV45kVW"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VphnS-M8BjZ5"},"source":["__Задача:__ предсказание баллов ЕГЭ ученика в зависимости от количества лет стажа его репетитора"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"i77tZbAd5plB","outputId":"784cb9ea-d0b1-4633-8ded-80edaa795b76"},"outputs":[{"data":{"text/plain":["array([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n","       [ 1,  1,  2,  5,  3,  0,  5, 10,  1,  2]])"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","              [1, 1, 2, 5, 3, 0, 5, 10, 1, 2]])\n","X"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"ejifaMBe6VaP","outputId":"190a541b-5c6d-48f6-8982-b513de5d7606"},"outputs":[{"data":{"text/plain":["(2, 10)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["X.shape"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"VsNrKi1Q6Wmh"},"outputs":[],"source":["y = [45, 55, 50, 55, 60, 35, 75, 80, 50, 60]"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["def call_mse(y, y_pred):\n","    err = np.mean((y-y_pred)**2)\n","    return err"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["def calc_mae(y, y_pred):\n","    err = np.mean(np.abs(y - y_pred))\n","    return err\n","\n","def calc_mse(y, y_pred):\n","    err = np.mean((y - y_pred)**2) # <=> 1/n * np.sum((y_pred - y)**2)\n","    return err"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**1 Подберите скорость обучения (alpha) и количество итераций**"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of objects = 10        \n","Learning rate = 0.01        \n","Initial weights = [1.  0.5] \n","\n","Iteration #0: W_new = [2.08 4.27], MSE = 3047.75\n","Iteration #10: W_new = [ 6.67106886 10.61676385], MSE = 749.71\n","Iteration #20: W_new = [ 9.49320908 10.25731657], MSE = 648.91\n","Iteration #30: W_new = [11.85740092  9.83349244], MSE = 570.46\n","Iteration #40: W_new = [13.86876921  9.46898661], MSE = 508.03\n","Iteration #50: W_new = [15.59085668  9.15672679], MSE = 457.73\n","Iteration #60: W_new = [17.07337653  8.88789585], MSE = 416.77\n","Iteration #70: W_new = [18.35601294  8.65530964], MSE = 383.06\n","Iteration #80: W_new = [19.47073522  8.45317196], MSE = 355.08\n","Iteration #90: W_new = [20.44350656  8.27677488], MSE = 331.65\n","Iteration #100: W_new = [21.29557245  8.12226587], MSE = 311.9\n","Iteration #110: W_new = [22.044442    7.98646992], MSE = 295.12\n","Iteration #120: W_new = [22.7046421   7.86675281], MSE = 280.78\n","Iteration #130: W_new = [23.2883015   7.76091518], MSE = 268.46\n","Iteration #140: W_new = [23.80560705  7.66710979], MSE = 257.81\n","Iteration #150: W_new = [24.26516249  7.5837765 ], MSE = 248.58\n","Iteration #160: W_new = [24.67427278  7.50959066], MSE = 240.53\n","Iteration #170: W_new = [25.03917079  7.44342203], MSE = 233.49\n","Iteration #180: W_new = [25.36519943  7.38430176], MSE = 227.31\n","Iteration #190: W_new = [25.65695861  7.33139573], MSE = 221.86\n","Iteration #200: W_new = [25.91842478  7.28398287], MSE = 217.05\n","Iteration #210: W_new = [26.15304857  7.24143747], MSE = 212.8\n","Iteration #220: W_new = [26.36383499  7.2032146 ], MSE = 209.02\n","Iteration #230: W_new = [26.55340974  7.16883814], MSE = 205.65\n","Iteration #240: W_new = [26.72407419  7.13789077], MSE = 202.66\n","Iteration #250: W_new = [26.87785132  7.11000566], MSE = 199.98\n","Iteration #260: W_new = [27.01652415  7.08485948], MSE = 197.59\n","Iteration #270: W_new = [27.14166815  7.06216655], MSE = 195.44\n","Iteration #280: W_new = [27.25467861  7.04167384], MSE = 193.52\n","Iteration #290: W_new = [27.35679393  7.02315681], MSE = 191.79\n","Iteration #300: W_new = [27.44911541  7.00641573], MSE = 190.24\n","Iteration #310: W_new = [27.53262425  6.99127269], MSE = 188.84\n","Iteration #320: W_new = [27.60819612  6.97756889], MSE = 187.58\n","Iteration #330: W_new = [27.67661373  6.96516242], MSE = 186.45\n","Iteration #340: W_new = [27.73857771  6.9539262 ], MSE = 185.42\n","Iteration #350: W_new = [27.79471602  6.94374639], MSE = 184.5\n","Iteration #360: W_new = [27.84559223  6.93452077], MSE = 183.66\n","Iteration #370: W_new = [27.89171262  6.92615755], MSE = 182.91\n","Iteration #380: W_new = [27.93353252  6.91857415], MSE = 182.23\n","Iteration #390: W_new = [27.9714618   6.91169626], MSE = 181.61\n","Iteration #400: W_new = [28.00586973  6.90545692], MSE = 181.05\n","Iteration #410: W_new = [28.03708926  6.89979574], MSE = 180.54\n","Iteration #420: W_new = [28.06542083  6.89465824], MSE = 180.08\n","Iteration #430: W_new = [28.0911357   6.88999525], MSE = 179.67\n","Iteration #440: W_new = [28.11447893  6.88576231], MSE = 179.29\n","Iteration #450: W_new = [28.13567205  6.88191927], MSE = 178.95\n","Iteration #460: W_new = [28.15491542  6.87842978], MSE = 178.64\n","Iteration #470: W_new = [28.17239031  6.87526098], MSE = 178.36\n","Iteration #480: W_new = [28.18826083  6.8723831 ], MSE = 178.1\n","Iteration #490: W_new = [28.20267557  6.86976921], MSE = 177.87\n"]}],"source":["n = X.shape[1]\n","alpha = 1e-2\n","W = np.array([1, 0.5])\n","print(f'Number of objects = {n} \\\n","       \\nLearning rate = {alpha} \\\n","       \\nInitial weights = {W} \\n')\n","\n","for i in range(500):\n","    y_pred = np.dot(W, X)\n","    err = calc_mse(y, y_pred)\n","    for k in range(W.shape[0]):\n","        W[k] -= alpha * (1/n * 2 * np.sum(X[k] * (y_pred - y)))\n","    if i % 10 == 0:\n","        alpha /= 1.1\n","        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err,2)}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["*2. В этом коде мы избавляемся от итераций по весам, но здесь есть ошибка, исправьте её."]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of objects = 10        \n","Learning rate = 0.01        \n","Initial weights = [1.  0.5] \n","\n","Iteration #0: W_new = [2.08 4.27], MSE = 3047.75\n","Iteration #10: W_new = [ 7.0011236 10.6169007], MSE = 738.65\n","Iteration #20: W_new = [10.3486292  10.10603105], MSE = 622.03\n","Iteration #30: W_new = [13.38789582  9.55618391], MSE = 525.24\n","Iteration #40: W_new = [16.16088505  9.05336203], MSE = 444.66\n","Iteration #50: W_new = [18.69110735  8.59454545], MSE = 377.58\n","Iteration #60: W_new = [20.99981865  8.17589626], MSE = 321.72\n","Iteration #70: W_new = [23.10641138  7.79389815], MSE = 275.22\n","Iteration #80: W_new = [25.02858024  7.44534246], MSE = 236.5\n","Iteration #90: W_new = [26.78247081  7.12730145], MSE = 204.27\n"]}],"source":["n = X.shape[1]\n","alpha = 1e-2\n","W = np.array([1, 0.5])\n","print(f'Number of objects = {n} \\\n","       \\nLearning rate = {alpha} \\\n","       \\nInitial weights = {W} \\n')\n","\n","for i in range(100):\n","    y_pred = np.dot(W, X)\n","    err = calc_mse(y, y_pred)\n","#     for k in range(W.shape[0]):\n","#         W[k] -= alpha * (1/n * 2 * np.sum(X[k] * (y_pred - y)))\n","    W -= alpha * (1/n * 2 * np.sum(X * (y_pred - y), axis=1))\n","    W_pred = W\n","    if i % 10 == 0:\n","        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err,2)}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Задание *3 (дополнительная): вместо того, чтобы задавать количество итераций, задайте условие остановки алгоритма - когда ошибка за итерацию начинает изменяться ниже определенного порога (упрощенный аналог параметра tol в линейной регрессии в sklearn)."]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of objects = 10        \n","Learning rate = 0.01        \n","Initial weights = [1.  0.5] \n","\n","Iteration #10: W_new = [ 6.64172205 10.62940003], MSE = 752.02\n","Iteration #20: W_new = [10.02900674 10.16329008], MSE = 632.72\n","Iteration #30: W_new = [13.09636548  9.60903915], MSE = 534.14\n","Iteration #40: W_new = [15.89487851  9.10159809], MSE = 452.07\n","Iteration #50: W_new = [18.44838865  8.63855875], MSE = 383.75\n","Iteration #60: W_new = [20.77834901  8.21605636], MSE = 326.86\n","Iteration #70: W_new = [22.90433054  7.83054239], MSE = 279.49\n","Iteration #80: W_new = [24.84419078  7.47877865], MSE = 240.06\n","Iteration #90: W_new = [26.61422391  7.15781043], MSE = 207.23\n","Iteration #100: W_new = [28.22929764  6.86494171], MSE = 179.9\n","Iteration #110: W_new = [29.70297804  6.59771249], MSE = 157.14\n","Iteration #120: W_new = [31.04764353  6.35387814], MSE = 138.19\n","Iteration #130: W_new = [32.27458888  6.13139052], MSE = 122.41\n","Iteration #140: W_new = [33.39412     5.92838081], MSE = 109.28\n","Iteration #150: W_new = [34.41564059  5.7431438 ], MSE = 98.35\n","Iteration #160: W_new = [35.34773109  5.57412356], MSE = 89.24\n","Iteration #170: W_new = [36.19822075  5.41990037], MSE = 81.66\n","Iteration #180: W_new = [36.9742534   5.27917882], MSE = 75.35\n","Iteration #190: W_new = [37.68234745  5.15077688], MSE = 70.1\n","Iteration #200: W_new = [38.32845066  5.03361602], MSE = 65.72\n","Iteration #210: W_new = [38.91799009  4.92671213], MSE = 62.08\n","Iteration #220: W_new = [39.45591767  4.82916726], MSE = 59.05\n","Iteration #230: W_new = [39.94675181  4.74016206], MSE = 56.52\n","Iteration #240: W_new = [40.39461537  4.65894891], MSE = 54.42\n","Iteration #250: W_new = [40.80327023  4.58484565], MSE = 52.67\n","Iteration #260: W_new = [41.17614898  4.51722984], MSE = 51.21\n","Iteration #270: W_new = [41.51638367  4.45553352], MSE = 50.0\n","Iteration #280: W_new = [41.82683215  4.39923848], MSE = 48.99\n","Iteration #290: W_new = [42.11010209  4.34787184], MSE = 48.15\n","Iteration #300: W_new = [42.36857287  4.30100215], MSE = 47.45\n","Iteration #310: W_new = [42.60441555  4.25823571], MSE = 46.87\n","Iteration #320: W_new = [42.81961114  4.21921331], MSE = 46.38\n","Iteration #330: W_new = [43.0159672   4.18360717], MSE = 45.98\n","Iteration #340: W_new = [43.19513307  4.1511182 ], MSE = 45.64\n","Iteration #350: W_new = [43.35861367  4.12147351], MSE = 45.36\n","Iteration #360: W_new = [43.50778219  4.0944241 ], MSE = 45.13\n","Iteration #370: W_new = [43.6438916   4.06974276], MSE = 44.93\n","Iteration #380: W_new = [43.76808516  4.04722217], MSE = 44.77\n","Iteration #390: W_new = [43.88140607  4.02667317], MSE = 44.64\n","Iteration #400: W_new = [43.98480618  4.00792316], MSE = 44.53\n","Iteration #410: W_new = [44.07915402  3.99081463], MSE = 44.43\n","Iteration #420: W_new = [44.16524207  3.97520389], MSE = 44.35\n","Iteration #430: W_new = [44.24379346  3.96095981], MSE = 44.29\n","Iteration #440: W_new = [44.31546799  3.94796274], MSE = 44.24\n","Iteration #450: W_new = [44.38086769  3.93610351], MSE = 44.19\n","Iteration #460: W_new = [44.44054191  3.92528251], MSE = 44.15\n","Iteration #470: W_new = [44.49499188  3.91540885], MSE = 44.12\n","Iteration #480: W_new = [44.54467498  3.90639958], MSE = 44.1\n","Iteration #490: W_new = [44.59000851  3.89817905], MSE = 44.08\n","Iteration #500: W_new = [44.63137328  3.89067818], MSE = 44.06\n","Iteration #510: W_new = [44.66911672  3.88383399], MSE = 44.04\n","Iteration #520: W_new = [44.70355587  3.87758898], MSE = 44.03\n"]}],"source":["n = X.shape[1]\n","alpha = 1e-2\n","W = np.array([1, 0.5])\n","print(f'Number of objects = {n} \\\n","       \\nLearning rate = {alpha} \\\n","       \\nInitial weights = {W} \\n')\n","\n","tol = 1e-3\n","y_pred = np.dot(W, X)\n","err = calc_mse(y, y_pred)\n","i = 1\n","\n","while (True):\n","    W -= alpha * (1/n * 2 * np.sum(X * (y_pred - y), axis=1))\n","    W_pred = W\n","    if i % 10 == 0:\n","        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err,2)}')\n","    \n","    y_pred = np.dot(W, X)\n","    err1 = calc_mse(y, y_pred)\n","    if abs(err1 - err) < tol:\n","        break\n","    err = err1\n","    i+=1"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Lesson_1_script.ipynb","provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"452c276e810072ac0d070a9ecbd74ba181ab2f9a45b11b5d9d043df0d8e763c9"}}},"nbformat":4,"nbformat_minor":0}
